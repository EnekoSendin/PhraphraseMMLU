{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from openai import OpenAI #estamos la clase concreta OpenAI del módulo openai\n",
    "from dotenv import load_dotenv #importamos una función concreta del módulo\n",
    "load_dotenv(\"template.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder a la clave de API de OpenAI\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Asegurarte de que la clave de API se haya cargado correctamente\n",
    "if api_key is None:\n",
    "    raise ValueError(\"La clave de API no está configurada en el archivo .env\")\n",
    "    \n",
    "client = OpenAI() #creando un objeto de la clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>option_a</th>\n",
       "      <th>option_b</th>\n",
       "      <th>option_c</th>\n",
       "      <th>option_d</th>\n",
       "      <th>answer</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For which of these two scenarios does the main...</td>\n",
       "      <td>Wrong, Wrong</td>\n",
       "      <td>Wrong, Not wrong</td>\n",
       "      <td>Not wrong, Wrong</td>\n",
       "      <td>Not wrong, Not wrong</td>\n",
       "      <td>D</td>\n",
       "      <td>moral_scenarios_test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For which of these two scenarios does the main...</td>\n",
       "      <td>Wrong, Wrong</td>\n",
       "      <td>Wrong, Not wrong</td>\n",
       "      <td>Not wrong, Wrong</td>\n",
       "      <td>Not wrong, Not wrong</td>\n",
       "      <td>A</td>\n",
       "      <td>moral_scenarios_test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For which of these two scenarios does the main...</td>\n",
       "      <td>Wrong, Wrong</td>\n",
       "      <td>Wrong, Not wrong</td>\n",
       "      <td>Not wrong, Wrong</td>\n",
       "      <td>Not wrong, Not wrong</td>\n",
       "      <td>D</td>\n",
       "      <td>moral_scenarios_test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For which of these two scenarios does the main...</td>\n",
       "      <td>Wrong, Wrong</td>\n",
       "      <td>Wrong, Not wrong</td>\n",
       "      <td>Not wrong, Wrong</td>\n",
       "      <td>Not wrong, Not wrong</td>\n",
       "      <td>B</td>\n",
       "      <td>moral_scenarios_test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For which of these two scenarios does the main...</td>\n",
       "      <td>Wrong, Wrong</td>\n",
       "      <td>Wrong, Not wrong</td>\n",
       "      <td>Not wrong, Wrong</td>\n",
       "      <td>Not wrong, Not wrong</td>\n",
       "      <td>D</td>\n",
       "      <td>moral_scenarios_test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction      option_a  \\\n",
       "0  For which of these two scenarios does the main...  Wrong, Wrong   \n",
       "1  For which of these two scenarios does the main...  Wrong, Wrong   \n",
       "2  For which of these two scenarios does the main...  Wrong, Wrong   \n",
       "3  For which of these two scenarios does the main...  Wrong, Wrong   \n",
       "4  For which of these two scenarios does the main...  Wrong, Wrong   \n",
       "\n",
       "           option_b          option_c              option_d answer  \\\n",
       "0  Wrong, Not wrong  Not wrong, Wrong  Not wrong, Not wrong      D   \n",
       "1  Wrong, Not wrong  Not wrong, Wrong  Not wrong, Not wrong      A   \n",
       "2  Wrong, Not wrong  Not wrong, Wrong  Not wrong, Not wrong      D   \n",
       "3  Wrong, Not wrong  Not wrong, Wrong  Not wrong, Not wrong      B   \n",
       "4  Wrong, Not wrong  Not wrong, Wrong  Not wrong, Not wrong      D   \n",
       "\n",
       "                     id  \n",
       "0  moral_scenarios_test  \n",
       "1  moral_scenarios_test  \n",
       "2  moral_scenarios_test  \n",
       "3  moral_scenarios_test  \n",
       "4  moral_scenarios_test  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_folder = os.getenv(\"DATASET_FOLDER\")\n",
    "dataset_path = str(dataset_folder) + \"MMLU_completo.xlsx\"\n",
    "\n",
    "df = pd.read_excel(dataset_path)\n",
    "#df = df.sample(20)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION DECLARATION\n",
    "\n",
    "#MODEL = \"gpt-4o-mini\"\n",
    "#MODEL = \"gpt-4o\"\n",
    "MODEL = \"gpt-4.1-nano\"\n",
    "\n",
    "#Generate description of multiple question\n",
    "def generate_description(instr,op_a,op_b,op_c,op_d):\n",
    "\tdescription = json.dumps({\n",
    "        \"instruction\": instr,\n",
    "        \"options\": {\n",
    "            \"A\": op_a,\n",
    "            \"B\": op_b,\n",
    "            \"C\": op_c,\n",
    "            \"D\": op_d\n",
    "        }\n",
    "    })\n",
    "\treturn description\n",
    "\n",
    "#Generate one task\n",
    "def generate_task(index,prompt,desc):\n",
    "\ttask = {\n",
    "        \"custom_id\": f\"task-{index}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            # Esto es lo que tendrías en tu llamada a la API de Chat Completions\n",
    "            \"model\": MODEL,\n",
    "            \"temperature\": 0,\n",
    "            \"response_format\": { \n",
    "                \"type\": \"json_object\"\n",
    "            },\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": desc\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    }\n",
    "\treturn task\n",
    "\n",
    "def extract_data_paraphrase(new_line):\n",
    "\tres = new_line[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "\tres = json.loads(res)\n",
    "\treturn res\n",
    "\n",
    "def get_keys(json_object):\n",
    "\tres = []\n",
    "\tfor i in json_object:\n",
    "\t\tres.append(i)\n",
    "\treturn res\n",
    "\n",
    "def create_task_from_json(json_object,index,prompt,rename_func=None):\n",
    "\tif (rename_func == None):\n",
    "\t\trename_func = ['instruction','option_a','option_b','option_c','option_d']\n",
    "\ttry:\n",
    "\t\tinstruction = json_object[rename_func[0]]\n",
    "\t\toption_a = json_object[rename_func[1]]\n",
    "\t\toption_b = json_object[rename_func[2]]\n",
    "\t\toption_c = json_object[rename_func[3]]\n",
    "\t\toption_d = json_object[rename_func[4]]\n",
    "\texcept:\n",
    "\t\tprint(json_object)\n",
    "\t\tprint(index)\n",
    "\n",
    "\tdescription = generate_description(\n",
    "\t\tinstruction, option_a, option_b, option_c, option_d,\n",
    "\t)\n",
    "    \n",
    "\ttask = generate_task(\n",
    "\t\tindex, prompt,description,\n",
    "\t)\n",
    "\treturn task\n",
    "\n",
    "def create_task_array_from_dataframe(df,prompt):\n",
    "\ttasks = []\n",
    "\tfor index, row in df.iterrows():\n",
    "\t\ttask = create_task_from_json(row,index,prompt)\n",
    "\t\ttasks.append(task)\n",
    "\treturn tasks\n",
    "\n",
    "\n",
    "def create_file_from_tasks(tasks,file_name):\n",
    "\twith open(file_name, 'w') as file:\n",
    "\t\tfor obj in tasks:\n",
    "\t\t\tfile.write(json.dumps(obj) + '\\n')\n",
    "\n",
    "\n",
    "def create_batch(file_name):\n",
    "\tbatch_file = client.files.create(\n",
    "\t\tfile = open(file_name, \"rb\"),\n",
    "\t\tpurpose = \"batch\"\n",
    "\t)\n",
    "\tbatch_job = client.batches.create(\n",
    "\t\tinput_file_id = batch_file.id,\n",
    "\t\tendpoint = \"/v1/chat/completions\",\n",
    "\t\tcompletion_window = \"24h\"\n",
    "\t)\n",
    "\treturn batch_job\n",
    "\n",
    "def get_line_file(file_name,line,extract_func):\n",
    "\twith open(file_name, 'r') as f:\n",
    "\t\tfor line_number, theline in enumerate(f):\n",
    "\t\t\tif line_number == line:\n",
    "\t\t\t\tres = theline\n",
    "\t\t\t\tbreak\n",
    "\tres = json.loads(res)\n",
    "\treturn extract_func(res)\n",
    "\n",
    "\n",
    "def extract_none(line):return line\n",
    "\n",
    "\n",
    "def create_task_array_from_filename(file_name,prompt,extract_func,rename_func,error_file):\n",
    "\ttasks = []\n",
    "\tnum_errors = 0\n",
    "\twith open(file_name, 'r') as f:\n",
    "\t\tlines = len(f.readlines())\n",
    "\n",
    "\tfor i in range(0,lines):\n",
    "\t\ttry:\n",
    "\t\t\tline_new = get_line_file(file_name,i,extract_func)\n",
    "\t\t\ttask = create_task_from_json(line_new,i,prompt,rename_func)\n",
    "\t\t\ttasks.append(task)\n",
    "\t\texcept:\n",
    "\t\t\tline_new = get_line_file(file_name.replace(\"_result\",\"\"),i,extract_none)\n",
    "\t\t\twith open(error_file, 'a') as f:\n",
    "\t\t\t\tf.write(json.dumps(line_new) + '\\n')\n",
    "\t\t\tnum_errors+=1\n",
    "\t\t\t#print(f\"error in line[{i}]:\\n{line_new}\")\n",
    "\tprint(f\"number of errors = {num_errors}\")\n",
    "\treturn tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROMPTS\n",
    "\n",
    "#PARAPHRASING PROMPT\n",
    "categorize_system_prompt_paraphrase ='''\n",
    "Your goal is to paraphrase multiple choice questions from JSON objects. You will be provided with a JSON object containing a multiple choice question and you will output a JSON object with the reworded question.\n",
    "\n",
    "For each row paraphrase the question while maintaining the original meaning and paraphrase the options as well. Ensure the paraphrase is at least 500 characters long between options and question.\n",
    "\n",
    "The output JSON objects should be in the following format:\n",
    "\n",
    "{paraphrased_question: string, option_a: string, option_b: string, option_c: string, option_d: string,}\n",
    "\n",
    "Ensure that the question is presented differently but conveys the same idea. Keep the JSON format in the output with '{' and '}'.\n",
    "'''\n",
    "\n",
    "#ANSWER PROMPT\n",
    "categorize_system_prompt_answer = '''\n",
    "Your goal is to evaluate multiple choice questions from JSON objects. You will be provided with a JSON object containing a multiple choice question and you will output a JSON object with the evaluation of the question.\n",
    "\n",
    "For each row evaluate the question.\n",
    "\n",
    "The output JSON objects should be in the following format:\n",
    "\n",
    "{answer: string, // The selected option key for the question, limited to 'A', 'B', 'C', or 'D'}\n",
    "\n",
    "Keep the JSON format in the answer with '{' and '}'.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set output folder\n",
    "output_folder = os.getenv(\"OUTPUT_FOLDER\")\n",
    "def out_file(file_name): return (str(output_folder) + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAPHRASING TASK\n",
    "tasks_array = [create_task_array_from_dataframe(df,categorize_system_prompt_paraphrase)]\n",
    "file_array = [out_file(\"batch_job_mmlu_nano_paraphrase.jsonl\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'paraphrased_question': \"Create a comprehensive truth table to analyze the logical structure of the given argument. After constructing the table, assess whether the argument holds as valid or invalid based on the truth values. If the argument is found to be invalid, select the option that provides a specific counterexample demonstrating its invalidity. Keep in mind that multiple counterexamples might exist, so consider different combinations of truth values for the involved propositions.\\n\\nThe argument involves the following premises: 'If P then Q' and 'Q and R', leading to the conclusion '~P and R'. Using the truth table, determine the validity of this argument and identify any counterexamples if it is invalid.\\n\\nOptions:\\nA. The argument is valid.\\nB. The argument is invalid; a counterexample occurs when P, R, and Q are all true.\\nC. The argument is invalid; a counterexample occurs when P and Q are true, but R is false.\\nD. The argument is invalid; a counterexample occurs when R and Q are true, but P is false.\"}\n",
      "4236\n",
      "{'paraphrased_question': \"In addressing the critique from the egalitarian perspective regarding a state's authority to deny entry, Wellman argues that states are capable of meeting their responsibilities to outsiders without necessarily granting them access to their borders. However, philosopher Fine believes that Wellman's explanation falls short because it overlooks certain important considerations. Specifically, Fine contends that simply asserting that states can fulfill their duties without allowing entry does not fully address the potential implications of exclusion, especially when individuals seek to pursue interests that are unique to that state. This raises questions about the adequacy of Wellman's reasoning in justifying exclusion, as it may ignore the broader consequences of denying entry to those who wish to engage in activities or pursuits that are closely tied to the state's identity or resources. Given this context, why does Fine find Wellman's response to be insufficient in defending the state's right to exclude? Options include: A) the belief that egalitarians are inherently aligned with utilitarian ideas, B) the fact that Wellman is himself an immigrant, C) the idea that excluding individuals who want to pursue specific interests within the state can still cause harm, or D) the notion that the idea of 'exporting justice' contains an internal contradiction.\"}\n",
      "4941\n",
      "{'paraphrased_question': 'Imagine a scenario where a driver, operating a brand-new vehicle, is driving cautiously within the legal speed limits when suddenly an 11-year-old girl unexpectedly runs into the street right in front of his car. Despite the driver immediately hitting the brakes and swerving to avoid hitting her, the collision occurs, resulting in the girl suffering broken legs. While the girl lies injured in the street awaiting emergency services, the driver approaches her and expresses remorse, explaining that it is his first time driving this particular car and that he is unsure of what caused the accident but feels responsible. He offers to cover all her medical expenses. After she is discharged from the hospital, her parents contact the driver, who refuses to pay, claiming that since the girl ran into the street, she was at fault, and he has witnesses to support this. He also mentions that if he were less kind, he might sue her parents for damages to his new car. If the girl’s parents, representing her, decide to sue the driver for damages, which of the following statements best describes the legal admissibility of the driver’s comments made after the accident? Options include: (A) The driver’s comments about his driving and his willingness to pay hospital bills are both relevant and admissible in determining negligence; (B) Only his statement about paying hospital bills is admissible, while his comments about his driving are not; (C) His statement about his driving is relevant and admissible for negligence, but his comments about paying hospital bills are excluded due to public policy; (D) Neither his comments about his driving nor his willingness to pay hospital bills are admissible in negligence proceedings.'}\n",
      "6239\n",
      "{'paraphrased_question': 'Can you identify the individual who was the mastermind behind the slave rebellion that took place in Southampton, Virginia, in the year 1831? This uprising was one of the most significant acts of resistance by enslaved Africans in the United States during the early 19th century, and its leader played a crucial role in challenging the oppressive system of slavery. The person responsible for orchestrating this revolt is well-known in American history for their defiance and the impact it had on the abolitionist movement. Among the options provided, who was the key figure associated with this historic insurrection?', 'option_a': 'John Brown, a radical abolitionist known for his violent efforts to end slavery, was not involved in the Southampton uprising but is famous for his later actions, including the raid on Harpers Ferry. Option B, Dred Scott, was an enslaved man whose legal case became a landmark in the fight against slavery, but he did not lead any insurrections. Option C, Nat Turner, was the leader of the 1831 Southampton slave rebellion, which was a significant and violent uprising. Option D, Harriet Tubman, was a renowned conductor of the Underground Railroad and an abolitionist, but she was not involved in this specific revolt.'}\n",
      "8785\n",
      "{'paraphrased_question': 'Out of the options provided, which one does not belong to the category of textiles or materials used for making fabrics, considering the common types of cloth and fabric materials? Among the choices listed, identify the item that is not typically classified as a fabric or textile material used in clothing or upholstery, but rather as a different type of material or product altogether.', 'option_a': 'Velveteen, a soft fabric resembling velvet but made from cotton or synthetic fibers, often used in clothing and upholstery, is a well-known textile material. Option B, Celotex, is actually a brand of insulation material made from polyisocyanurate or other foam-based substances, primarily used in building insulation rather than fabric production. Option C, Seersucker, is a lightweight, puckered fabric often used in summer clothing, making it a recognized textile. Option D, Tencel, is a brand name for lyocell, a type of sustainable, biodegradable fabric made from cellulose fibers, widely used in apparel. Therefore, the item that does not qualify as a fabric is Celotex, as it is an insulation material and not a textile fabric used in clothing or furnishings.'}\n",
      "8995\n",
      "{'paraphrased_question': \"In the 1967 James Bond parody film 'Casino Royale,' which character is portrayed by the actor Woody Allen, known for his comedic style and distinctive persona? Among the options provided, identify the name of the character that Woody Allen brought to life in this satirical take on the classic spy series.\", 'option_a': \"Dr Evil, a comically exaggerated villain often associated with parody films, is not the character played by Woody Allen in 'Casino Royale' but is instead a different comedic villain from another franchise. Option_b: Q, the inventive quartermaster responsible for providing Bond with gadgets, is a recurring character in the Bond series but was not portrayed by Woody Allen in this particular film. Option_c: Little Jimmy Bond, a humorous and diminutive version of the famous spy, is a character that appears in the film as a parody, and Woody Allen's role is associated with this name. Option_d: M, the authoritative head of MI6, is a key figure in the Bond universe but was not played by Woody Allen in the 1967 'Casino Royale'.\"}\n",
      "9109\n",
      "{'paraphrased_question': 'Which of the listed foods is most commonly associated with the risk of contracting salmonella poisoning when consumed? Consider the options carefully, as some foods are more prone to harboring this bacteria than others, especially if not prepared or cooked properly. Among the choices provided, identify the item that is most likely to cause salmonella infection if contaminated and ingested without adequate safety measures.', 'option_a': 'fresh carrots, which are often eaten raw and can sometimes carry bacteria if not washed thoroughly, but are less commonly linked to salmonella compared to other foods; option_b: chicken, a poultry product that is frequently associated with salmonella contamination if not cooked to the proper internal temperature; option_c: tofu, a soy-based protein that can carry bacteria if contaminated during processing but is generally less associated with salmonella; option_d: cooked rice, which can sometimes harbor bacteria if left at unsafe temperatures, but is less commonly the source of salmonella compared to poultry.'}\n",
      "9440\n",
      "{'paraphrased_question': \"Based on the ideas expressed in the first source, which method does the author support as an effective strategy for reaching their social or political objectives? The author emphasizes the importance of creating a situation of tension that compels a community to confront issues it has previously refused to address, advocating for nonviolent methods to provoke change. This approach involves dramatizing problems to make them impossible to ignore, fostering constructive tension that can lead to growth and understanding, much like Socrates' philosophical method of stimulating thought through tension. The author explicitly distinguishes this form of tension from violent conflict, highlighting its role in encouraging societal progress and enlightenment. Considering these perspectives, which of the following tactics aligns with the author's endorsed approach to social activism and change? Options include violent overthrow, nonviolent resistance, appeasement, or legal action, with the emphasis on nonviolent resistance as the preferred method.\"}\n",
      "9556\n",
      "{'paraphrased_question': 'Imagine you have conducted a regression analysis based on a dataset comprising 27 quarterly data points, where the model is specified as follows: the dependent variable y_t is expressed as a linear combination of an intercept term, a coefficient multiplied by x_2, another coefficient multiplied by x_{3t}, and an error term u_t. In this context, you are interested in testing the null hypothesis that the coefficient associated with x_{3t} equals 1, using a two-sided test at a 5% significance level. To perform this hypothesis test accurately, what is the critical value you should compare your test statistic against? The options provided are: A) 1.64, B) 1.71, C) 2.06, and D) 1.96.'}\n",
      "11020\n",
      "number of errors = 0\n"
     ]
    }
   ],
   "source": [
    "file_name = out_file(\"batch_job_mmlu_nano_paraphrase_result.jsonl\")\n",
    "rename_func = ['paraphrased_question','option_a','option_b','option_c','option_d']\n",
    "\n",
    "error_file_name = out_file(\"batch_job_mmlu_answer_paraphrase_error.jsonl\")\n",
    "\n",
    "paraphrased_task = create_task_array_from_filename(file_name,categorize_system_prompt_answer,extract_data_paraphrase,rename_func,error_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_jo_error= create_batch(error_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='batch_680289ac091c819098f69d4671e12c23', completion_window='24h', created_at=1744996780, endpoint='/v1/chat/completions', input_file_id='file-3KY3E5G1FXXNUctzF9EBN9', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1744996989, error_file_id=None, errors=None, expired_at=None, expires_at=1745083180, failed_at=None, finalizing_at=1744996986, in_progress_at=1744996781, metadata=None, output_file_id='file-LZ3PtZVbN9aUkZ23RZWL65', request_counts=BatchRequestCounts(completed=22, failed=0, total=22))\n",
      "completed\n"
     ]
    }
   ],
   "source": [
    "batch = ba_jo_error\n",
    "batch = client.batches.retrieve(batch.id)\n",
    "print(batch)\n",
    "result_file_id = batch.output_file_id\n",
    "print(batch.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = ba_jo_error\n",
    "batch = client.batches.retrieve(batch.id)\n",
    "result_file_id = batch.output_file_id\n",
    "\n",
    "result = client.files.content(result_file_id).content\n",
    "\n",
    "result_file_name = error_file_name.replace(\".json\",\"_result.json\")\n",
    "\n",
    "with open(result_file_name, 'wb') as file:\n",
    "\tfile.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in line[3973]:\n",
      "{'custom_id': 'task-3973', 'method': 'POST', 'url': '/v1/chat/completions', 'body': {'model': 'gpt-4.1-nano', 'temperature': 0, 'response_format': {'type': 'json_object'}, 'messages': [{'role': 'system', 'content': \"\\nYour goal is to paraphrase multiple choice questions from JSON objects. You will be provided with a JSON object containing a multiple choice question and you will output a JSON object with the reworded question.\\n\\nFor each row paraphrase the question while maintaining the original meaning and paraphrase the options as well. Ensure the paraphrase is at least 500 characters long between options and question.\\n\\nThe output JSON objects should be in the following format:\\n\\n{paraphrased_question: string, option_a: string, option_b: string, option_c: string, option_d: string,}\\n\\nEnsure that the question is presented differently but conveys the same idea. Keep the JSON format in the output with '{' and '}'.\\n\"}, {'role': 'user', 'content': '{\"instruction\": \"Find the degree for the given field extension Q(sqrt(2) + sqrt(3)) over Q.\", \"options\": {\"A\": \"0\", \"B\": \"4\", \"C\": \"2\", \"D\": \"6\"}}'}]}}\n",
      "{'paraphrased_question': \"Create a comprehensive truth table to analyze the logical structure of the given argument. After constructing the table, assess whether the argument holds as valid or invalid based on the truth values. If the argument is found to be invalid, select the option that provides a specific counterexample demonstrating its invalidity. Keep in mind that multiple counterexamples might exist, so consider different combinations of truth values for the involved propositions.\\n\\nThe argument involves the following premises: 'If P then Q' and 'Q and R', leading to the conclusion '~P and R'. Using the truth table, determine the validity of this argument and identify any counterexamples if it is invalid.\\n\\nOptions:\\nA. The argument is valid.\\nB. The argument is invalid; a counterexample occurs when P, R, and Q are all true.\\nC. The argument is invalid; a counterexample occurs when P and Q are true, but R is false.\\nD. The argument is invalid; a counterexample occurs when R and Q are true, but P is false.\"}\n",
      "4236\n",
      "error in line[4236]:\n",
      "{'custom_id': 'task-4236', 'method': 'POST', 'url': '/v1/chat/completions', 'body': {'model': 'gpt-4.1-nano', 'temperature': 0, 'response_format': {'type': 'json_object'}, 'messages': [{'role': 'system', 'content': \"\\nYour goal is to paraphrase multiple choice questions from JSON objects. You will be provided with a JSON object containing a multiple choice question and you will output a JSON object with the reworded question.\\n\\nFor each row paraphrase the question while maintaining the original meaning and paraphrase the options as well. Ensure the paraphrase is at least 500 characters long between options and question.\\n\\nThe output JSON objects should be in the following format:\\n\\n{paraphrased_question: string, option_a: string, option_b: string, option_c: string, option_d: string,}\\n\\nEnsure that the question is presented differently but conveys the same idea. Keep the JSON format in the output with '{' and '}'.\\n\"}, {'role': 'user', 'content': '{\"instruction\": \" Construct a complete truth table for the following argument. Then, using the truth table, determine whether the argument is valid or invalid. If the argument is invalid, choose an option which presents a counterexample. (There may be other counterexamples as well.)\\\\nP \\\\u2283 Q\\\\nQ \\\\u00b7 R / ~P \\\\u00b7 R\", \"options\": {\"A\": \"Valid\", \"B\": \"Invalid. Counterexample when P, R, and Q are true\", \"C\": \"Invalid. Counterexample when P and Q are true and R is false\", \"D\": \"Invalid. Counterexample when R and Q are true and P is false\"}}'}]}}\n",
      "error in line[4369]:\n",
      "{'custom_id': 'task-4369', 'method': 'POST', 'url': '/v1/chat/completions', 'body': {'model': 'gpt-4.1-nano', 'temperature': 0, 'response_format': {'type': 'json_object'}, 'messages': [{'role': 'system', 'content': \"\\nYour goal is to paraphrase multiple choice questions from JSON objects. You will be provided with a JSON object containing a multiple choice question and you will output a JSON object with the reworded question.\\n\\nFor each row paraphrase the question while maintaining the original meaning and paraphrase the options as well. Ensure the paraphrase is at least 500 characters long between options and question.\\n\\nThe output JSON objects should be in the following format:\\n\\n{paraphrased_question: string, option_a: string, option_b: string, option_c: string, option_d: string,}\\n\\nEnsure that the question is presented differently but conveys the same idea. Keep the JSON format in the output with '{' and '}'.\\n\"}, {'role': 'user', 'content': '{\"instruction\": \"An object rests on a plane, with an angle of incline, ?, an acceleration due to gravity, g, and a coefficient of friction \\\\u00b5 between the object and the plane. Which of the following gives the acceleration of the object?\", \"options\": {\"A\": \"a = g sin ?\", \"B\": \"a = g (sin ? \\\\u2013 cos ?)\", \"C\": \"a = g (cos ? \\\\u2013 \\\\u00b5 sin ?)\", \"D\": \"a = g (sin ? \\\\u2013 \\\\u00b5 cos ?)\"}}'}]}}\n",
      "{'paraphrased_question': \"In addressing the critique from the egalitarian perspective regarding a state's authority to deny entry, Wellman argues that states are capable of meeting their responsibilities to outsiders without necessarily granting them access to their borders. However, philosopher Fine believes that Wellman's explanation falls short because it overlooks certain important considerations. Specifically, Fine contends that simply asserting that states can fulfill their duties without allowing entry does not fully address the potential implications of exclusion, especially when individuals seek to pursue interests that are unique to that state. This raises questions about the adequacy of Wellman's reasoning in justifying exclusion, as it may ignore the broader consequences of denying entry to those who wish to engage in activities or pursuits that are closely tied to the state's identity or resources. Given this context, why does Fine find Wellman's response to be insufficient in defending the state's right to exclude? Options include: A) the belief that egalitarians are inherently aligned with utilitarian ideas, B) the fact that Wellman is himself an immigrant, C) the idea that excluding individuals who want to pursue specific interests within the state can still cause harm, or D) the notion that the idea of 'exporting justice' contains an internal contradiction.\"}\n",
      "4941\n",
      "error in line[4941]:\n",
      "{'custom_id': 'task-4941', 'method': 'POST', 'url': '/v1/chat/completions', 'body': {'model': 'gpt-4.1-nano', 'temperature': 0, 'response_format': {'type': 'json_object'}, 'messages': [{'role': 'system', 'content': \"\\nYour goal is to paraphrase multiple choice questions from JSON objects. You will be provided with a JSON object containing a multiple choice question and you will output a JSON object with the reworded question.\\n\\nFor each row paraphrase the question while maintaining the original meaning and paraphrase the options as well. Ensure the paraphrase is at least 500 characters long between options and question.\\n\\nThe output JSON objects should be in the following format:\\n\\n{paraphrased_question: string, option_a: string, option_b: string, option_c: string, option_d: string,}\\n\\nEnsure that the question is presented differently but conveys the same idea. Keep the JSON format in the output with '{' and '}'.\\n\"}, {'role': 'user', 'content': '{\"instruction\": \" Wellman\\'s response to the \\\\\"egalitarian\\\\\" objection to the state\\'s right to exclude is that states can fulfill their duties to outsiders without allowing them into their territory. Fine thinks Wellman\\'s response is insufficient because\", \"options\": {\"A\": \"egalitarians are committed to utilitarian principles.\", \"B\": \"Wellman himself is an immigrant.\", \"C\": \"excluding people who wish to pursue interests specific to that state is still potentially harmful.\", \"D\": \"the concept of \\\\\"exporting justice\\\\\" is internally contradictory.\"}}'}]}}\n",
      "error in line[5039]:\n",
      "{'custom_id': 'task-5039', 'method': 'POST', 'url': '/v1/chat/completions', 'body': {'model': 'gpt-4.1-nano', 'temperature': 0, 'response_format': {'type': 'json_object'}, 'messages': [{'role': 'system', 'content': \"\\nYour goal is to paraphrase multiple choice questions from JSON objects. You will be provided with a JSON object containing a multiple choice question and you will output a JSON object with the reworded question.\\n\\nFor each row paraphrase the question while maintaining the original meaning and paraphrase the options as well. Ensure the paraphrase is at least 500 characters long between options and question.\\n\\nThe output JSON objects should be in the following format:\\n\\n{paraphrased_question: string, option_a: string, option_b: string, option_c: string, option_d: string,}\\n\\nEnsure that the question is presented differently but conveys the same idea. Keep the JSON format in the output with '{' and '}'.\\n\"}, {'role': 'user', 'content': '{\"instruction\": \" Which of the following is not an example of a natural right that Locke uses?\", \"options\": {\"A\": \"the right to life\", \"B\": \"the right to liberty\", \"C\": \"the right to citizenship\", \"D\": \"the right to property\"}}'}]}}\n",
      "error in line[5094]:\n",
      "{'custom_id': 'task-5094', 'method': 'POST', 'url': '/v1/chat/completions', 'body': {'model': 'gpt-4.1-nano', 'temperature': 0, 'response_format': {'type': 'json_object'}, 'messages': [{'role': 'system', 'content': \"\\nYour goal is to paraphrase multiple choice questions from JSON objects. You will be provided with a JSON object containing a multiple choice question and you will output a JSON object with the reworded question.\\n\\nFor each row paraphrase the question while maintaining the original meaning and paraphrase the options as well. Ensure the paraphrase is at least 500 characters long between options and question.\\n\\nThe output JSON objects should be in the following format:\\n\\n{paraphrased_question: string, option_a: string, option_b: string, option_c: string, option_d: string,}\\n\\nEnsure that the question is presented differently but conveys the same idea. Keep the JSON format in the output with '{' and '}'.\\n\"}, {'role': 'user', 'content': '{\"instruction\": \"This question refers to the following information.\\\\n\\\\\"But you, my dear Pangloss,\\\\\" said Candide, \\\\\"how can it be that I behold you again?\\\\\"\\\\n\\\\\"It is true,\\\\\" said Pangloss, \\\\\"that you saw me hanged&\\\\u2026.A surgeon purchased my body, carried home, and dissected me. He began with making a crucial incision on me from the navel to the clavicula. One could not have been worse hanged than I was. The executioner of the Holy Inquisition was a sub-deacon, and knew how to burn people marvellously well, but he was not accustomed to hanging. The cord was wet and did not slip properly, and besides it was badly tied; in short, I still drew my breath, when the crucial incision made me give such a frightful scream that my surgeon fell flat upon his back&\\\\u2026[At length he] sewed up my wounds; his wife even nursed me. I was upon my legs at the end of fifteen days&\\\\u2026.\\\\nOne day I took it into my head to step into a mosque, where I saw an old Iman and a very pretty young devotee who was saying her paternosters&\\\\u2026.She dropped her bouquet; I picked it up, and presented it to her with a profound reverence. I was so long in delivering it that the Iman began to get angry, and seeing that I was a Christian he called out for help. They carried me before the cadi, who ordered me a hundred lashes on the soles of the feet and sent me to the galleys. I was chained to the very same galley and the same bench as the young Baron. On board this galley there were four young men from Marseilles, five Neapolitan priests, and two monks from Corfu, who told us similar adventures happened daily. The Baron maintained that he had suffered greater injustice than I&\\\\u2026.We were continually disputing, and received twenty lashes with a bull\\'s pizzle when the concatenation of universal events brought you to our galley, and you were good enough to ransom us.\\\\\"\\\\n\\\\\"Well, my dear Pangloss,\\\\\" said Candide to him, \\\\\"when you had been hanged, dissected, whipped, and were tugging at the oar, did you always think that everything happens for the best?\\\\\"\\\\n\\\\\"I am still of my first opinion,\\\\\" answered Pangloss, \\\\\"for I am a philosopher and I cannot retract, especially as Leibnitz could never be wrong; and besides, the pre-established harmony is the finest thing in the world, and so is his plenum and materia subtilis.\\\\\"\\\\nVoltaire, French Enlightenment writer, Candide, 1759\\\\nThe themes of the passage and the mode in which Pangloss tells them show the influence of\", \"options\": {\"A\": \"Medievalism\", \"B\": \"Empiricism\", \"C\": \"Rationalism\", \"D\": \"Romanticism\"}}'}]}}\n",
      "{'paraphrased_question': 'Imagine a scenario where a driver, operating a brand-new vehicle, is driving cautiously within the legal speed limits when suddenly an 11-year-old girl unexpectedly runs into the street right in front of his car. Despite the driver immediately hitting the brakes and swerving to avoid hitting her, the collision occurs, resulting in the girl suffering broken legs. While the girl lies injured in the street awaiting emergency services, the driver approaches her and expresses remorse, explaining that it is his first time driving this particular car and that he is unsure of what caused the accident but feels responsible. He offers to cover all her medical expenses. After she is discharged from the hospital, her parents contact the driver, who refuses to pay, claiming that since the girl ran into the street, she was at fault, and he has witnesses to support this. He also mentions that if he were less kind, he might sue her parents for damages to his new car. If the girl’s parents, representing her, decide to sue the driver for damages, which of the following statements best describes the legal admissibility of the driver’s comments made after the accident? Options include: (A) The driver’s comments about his driving and his willingness to pay hospital bills are both relevant and admissible in determining negligence; (B) Only his statement about paying hospital bills is admissible, while his comments about his driving are not; (C) His statement about his driving is relevant and admissible for negligence, but his comments about paying hospital bills are excluded due to public policy; (D) Neither his comments about his driving nor his willingness to pay hospital bills are admissible in negligence proceedings.'}\n",
      "6239\n",
      "error in line[6239]:\n",
      "{'custom_id': 'task-6239', 'method': 'POST', 'url': '/v1/chat/completions', 'body': {'model': 'gpt-4.1-nano', 'temperature': 0, 'response_format': {'type': 'json_object'}, 'messages': [{'role': 'system', 'content': \"\\nYour goal is to paraphrase multiple choice questions from JSON objects. You will be provided with a JSON object containing a multiple choice question and you will output a JSON object with the reworded question.\\n\\nFor each row paraphrase the question while maintaining the original meaning and paraphrase the options as well. Ensure the paraphrase is at least 500 characters long between options and question.\\n\\nThe output JSON objects should be in the following format:\\n\\n{paraphrased_question: string, option_a: string, option_b: string, option_c: string, option_d: string,}\\n\\nEnsure that the question is presented differently but conveys the same idea. Keep the JSON format in the output with '{' and '}'.\\n\"}, {'role': 'user', 'content': '{\"instruction\": \"A driver had a new car and, as he was carefully driving within the posted speed limit, a girl, aged 11, suddenly darted into the street in front of his car. Although\\\\\\\\he driver immediately applied his brakes and swerved to avoid the girl, the cat hit the girl, fracturing her legs. As the girl was lying in the street awaiting an ambulance, the driver rushed over to her and said: \\\\\"Im terribly sorry. This is the first time I ever drove this car. I don\\'t know what happened, but it must have been my fault. Send me all your hospital bills. I\\'fl pay for everything. \\\\\"When the girl was later released from the hospital, her parents contacted the driver who refused to pay anything. The driver told the girl\\'s mother, \\\\\"Since your daughter ran into the street, it was her fault. I have witnesses who saw what she did. If I weren\\'t such a nice guy, I\\'d sue you for the damage to my new car. \\\\\"If the girl\\'s parents, on her behalf, sue the driver in tort, which of the following is the most accurate statement regarding the driver\\'s post-accident statements?\", \"options\": {\"A\": \"The driver\\'s statement regarding his operation of the car, as well as his statement concerning payment of the hospital bills, are both admissible on the issue of negligence.\", \"B\": \"The driver\\'s statement regarding payment of the hospital bills is admissible, but his statement concerning his operation of the car is not admissible.\", \"C\": \"The driver\\'s statement regarding his operation of the car is admissible on the issue of negligence, but his statement concerning payment of the hospital bills is not admissible in accordance with public policy considerations.\", \"D\": \"Neither the driver\\'s statement regarding his operation of the car nor his statement concerning payment of the hospital bills is admissible on the issue of negligence.\"}}'}]}}\n",
      "error in line[6920]:\n",
      "{'custom_id': 'task-6920', 'method': 'POST', 'url': '/v1/chat/completions', 'body': {'model': 'gpt-4.1-nano', 'temperature': 0, 'response_format': {'type': 'json_object'}, 'messages': [{'role': 'system', 'content': \"\\nYour goal is to paraphrase multiple choice questions from JSON objects. You will be provided with a JSON object containing a multiple choice question and you will output a JSON object with the reworded question.\\n\\nFor each row paraphrase the question while maintaining the original meaning and paraphrase the options as well. Ensure the paraphrase is at least 500 characters long between options and question.\\n\\nThe output JSON objects should be in the following format:\\n\\n{paraphrased_question: string, option_a: string, option_b: string, option_c: string, option_d: string,}\\n\\nEnsure that the question is presented differently but conveys the same idea. Keep the JSON format in the output with '{' and '}'.\\n\"}, {'role': 'user', 'content': '{\"instruction\": \"To prove a discriminatory classification, it must be shown that the government had intent to discriminate. Such intent can be shown by all but which of the following?\", \"options\": {\"A\": \"A law that is discriminatory on its face.\", \"B\": \"A discriminatory application of a facially neutral law.\", \"C\": \"A discriminatory effect.\", \"D\": \"A discriminatory motive.\"}}'}]}}\n",
      "error in line[7104]:\n",
      "{'custom_id': 'task-7104', 'method': 'POST', 'url': '/v1/chat/completions', 'body': {'model': 'gpt-4.1-nano', 'temperature': 0, 'response_format': {'type': 'json_object'}, 'messages': [{'role': 'system', 'content': \"\\nYour goal is to paraphrase multiple choice questions from JSON objects. You will be provided with a JSON object containing a multiple choice question and you will output a JSON object with the reworded question.\\n\\nFor each row paraphrase the question while maintaining the original meaning and paraphrase the options as well. Ensure the paraphrase is at least 500 characters long between options and question.\\n\\nThe output JSON objects should be in the following format:\\n\\n{paraphrased_question: string, option_a: string, option_b: string, option_c: string, option_d: string,}\\n\\nEnsure that the question is presented differently but conveys the same idea. Keep the JSON format in the output with '{' and '}'.\\n\"}, {'role': 'user', 'content': '{\"instruction\": \"A boyfriend decided to rob a grocery store after he was let go during a labor dispute. The boyfriend asked his girlfriend to drive the getaway car, to which she agreed, on the condition that no loaded weapons were used during the robbery. On the day of the robbery, the boyfriend and his girlfriend drove to the grocery store. Unknown to the girlfriend, the boyfriend entered the store with a loaded gun. The boyfriend approached one of the cashiers and told him to fill a bag with all the money from the register. When the cashier refused, the boyfriend shot and killed him. He then turned to the next cashier and pointed his gun at her. The cashier suffered a heart attack and died. The boyfriend then took the money from the registers himself and exited the store. One of the customers had called the police, and they were waiting outside. A shootout ensued, and the boyfriend was killed by the police. If this jurisdiction follows the agency theory of felony murder, the girlfriend is guilty if how many counts of murder?\", \"options\": {\"A\": \"1\", \"B\": \"2\", \"C\": \"3\", \"D\": \"None.\"}}'}]}}\n",
      "error in line[7278]:\n",
      "{'custom_id': 'task-7278', 'method': 'POST', 'url': '/v1/chat/completions', 'body': {'model': 'gpt-4.1-nano', 'temperature': 0, 'response_format': {'type': 'json_object'}, 'messages': [{'role': 'system', 'content': \"\\nYour goal is to paraphrase multiple choice questions from JSON objects. You will be provided with a JSON object containing a multiple choice question and you will output a JSON object with the reworded question.\\n\\nFor each row paraphrase the question while maintaining the original meaning and paraphrase the options as well. Ensure the paraphrase is at least 500 characters long between options and question.\\n\\nThe output JSON objects should be in the following format:\\n\\n{paraphrased_question: string, option_a: string, option_b: string, option_c: string, option_d: string,}\\n\\nEnsure that the question is presented differently but conveys the same idea. Keep the JSON format in the output with '{' and '}'.\\n\"}, {'role': 'user', 'content': '{\"instruction\": \"A city \\\\\"flow control\\\\\" ordinance mandated that all solid waste that was within the limits of the town was to be transported to a local facility in the city for processing before it could be sent to other states for further disposal. A solid waste processor sued the city in federal court claiming that the ordinance discriminated based on local economic protectionism. The city responded that the ordinance did not discriminate because it does not differentiate solid waste due to geographic origin. All solid waste, regardless of origin, must be processed and made environmentally safe at the transfer station before it leaves town. Will the federal court rule that the flow control ordinance is a discriminatory law against the free flow of interstate commerce?\", \"options\": {\"A\": \"Yes, because it allows only the favored operator to process waste that is within the limits of the town, to the exclusion of outside processors who might be interested in getting some of the business.\", \"B\": \"Yes, because it requires processors to come into the state to be allowed to do processing instead of being able receive the waste at their out-of-state location.\", \"C\": \"No, because the city did not discriminate against anyone\\'s waste, if it was in the city limits the state from where the material originated did not come into consideration.\", \"D\": \"No, because the city simply wanted to assure that the solid waste leaving the area was not environmentally harmful.\"}}'}]}}\n",
      "error in line[7465]:\n",
      "{'custom_id': 'task-7465', 'method': 'POST', 'url': '/v1/chat/completions', 'body': {'model': 'gpt-4.1-nano', 'temperature': 0, 'response_format': {'type': 'json_object'}, 'messages': [{'role': 'system', 'content': \"\\nYour goal is to paraphrase multiple choice questions from JSON objects. You will be provided with a JSON object containing a multiple choice question and you will output a JSON object with the reworded question.\\n\\nFor each row paraphrase the question while maintaining the original meaning and paraphrase the options as well. Ensure the paraphrase is at least 500 characters long between options and question.\\n\\nThe output JSON objects should be in the following format:\\n\\n{paraphrased_question: string, option_a: string, option_b: string, option_c: string, option_d: string,}\\n\\nEnsure that the question is presented differently but conveys the same idea. Keep the JSON format in the output with '{' and '}'.\\n\"}, {'role': 'user', 'content': '{\"instruction\": \"Hearing loss occurs more frequently for\", \"options\": {\"A\": \"Men than women\", \"B\": \"Women than men\", \"C\": \"People who already have some loss of vision\", \"D\": \"People who are obese\"}}'}]}}\n"
     ]
    }
   ],
   "source": [
    "#ANSWERING TASK\n",
    "tasks_array = [\n",
    "\tcreate_task_array_from_dataframe(df,categorize_system_prompt_answer),\n",
    "\tparaphrased_task\n",
    "\t]\n",
    "file_array = [out_file(\"batch_job_mmlu_nano_answer_original.jsonl\"),out_file(\"batch_job_mmlu_nano_answer_paraphrase.jsonl\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERATE TASK FILES\n",
    "for i in range(0,len(tasks_array)):\n",
    "\tcreate_file_from_tasks(tasks_array[i],file_array[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERATE BATCH\n",
    "batch_jobs = []\n",
    "for i in range(0,len(tasks_array)):\n",
    "\tba_jo= create_batch(file_array[i])\n",
    "\tbatch_jobs.append(ba_jo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='batch_6802635350a48190bd2634640d94d4f4', completion_window='24h', created_at=1744986963, endpoint='/v1/chat/completions', input_file_id='file-1jTwssaSzY8DqVJsfU8r7B', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1744990785, error_file_id=None, errors=None, expired_at=None, expires_at=1745073363, failed_at=None, finalizing_at=1744989168, in_progress_at=1744986968, metadata=None, output_file_id='file-KZPCP2hRNMR2U6G54Aak8s', request_counts=BatchRequestCounts(completed=14042, failed=0, total=14042))\n",
      "completed\n"
     ]
    }
   ],
   "source": [
    "#COMPLETION_CHECK\n",
    "for i in range(0,len(batch_jobs)):\n",
    "\tbatch = batch_jobs[i]\n",
    "\tbatch = client.batches.retrieve(batch.id)\n",
    "\tprint(batch)\n",
    "\tresult_file_id = batch.output_file_id\n",
    "\tprint(batch.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OUTPUT FILES GENERATOR\n",
    "for i in range(0,len(batch_jobs)):\n",
    "\tbatch = batch_jobs[i]\n",
    "\tbatch = client.batches.retrieve(batch.id)\n",
    "\tresult_file_id = batch.output_file_id\n",
    "\n",
    "\tresult = client.files.content(result_file_id).content\n",
    "\n",
    "\tresult_file_name = file_array[i].replace(\".json\",\"_result.json\")\n",
    "\n",
    "\twith open(result_file_name, 'wb') as file:\n",
    "\t\tfile.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output_files/batch_job_mmlu_nano_answer_original_result.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 56\u001b[0m\n\u001b[0;32m     53\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(rows),stats\n\u001b[0;32m     55\u001b[0m file_name \u001b[38;5;241m=\u001b[39m out_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinalResults_gpt41nano.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m clean_dtset,stat \u001b[38;5;241m=\u001b[39m \u001b[43mclean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mExcelWriter(file_name) \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[0;32m     60\u001b[0m \tclean_dtset\u001b[38;5;241m.\u001b[39mto_excel(writer, sheet_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResults\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[24], line 25\u001b[0m, in \u001b[0;36mclean\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,lines):\n\u001b[0;32m     24\u001b[0m \tdt_ph \u001b[38;5;241m=\u001b[39m get_line_file(f_ph,i,extract_data_paraphrase)\n\u001b[1;32m---> 25\u001b[0m \tdt_a \u001b[38;5;241m=\u001b[39m \u001b[43mget_line_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mextract_data_paraphrase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \tdt_ph_a \u001b[38;5;241m=\u001b[39m get_line_file(f_ph_a,i,extract_data_paraphrase)\n\u001b[0;32m     28\u001b[0m \trow \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[i]\n",
      "Cell \u001b[1;32mIn[8], line 107\u001b[0m, in \u001b[0;36mget_line_file\u001b[1;34m(file_name, line, extract_func)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_line_file\u001b[39m(file_name,line,extract_func):\n\u001b[1;32m--> 107\u001b[0m \t\u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    108\u001b[0m \t\t\u001b[38;5;28;01mfor\u001b[39;00m line_number, theline \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(f):\n\u001b[0;32m    109\u001b[0m \t\t\t\u001b[38;5;28;01mif\u001b[39;00m line_number \u001b[38;5;241m==\u001b[39m line:\n",
      "File \u001b[1;32mc:\\Users\\Eneko\\Documents\\UniUPM\\BECA\\IA_quest_paraphr\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output_files/batch_job_mmlu_nano_answer_original_result.jsonl'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Eliminar caracteres de control ASCII (excepto saltos de línea/tabulación)\n",
    "        text = re.sub(r\"[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F]\", \"\", text)\n",
    "        return text.strip()\n",
    "    return text\n",
    "\n",
    "#Cleaning function\n",
    "def clean():\n",
    "\twith open(out_file(\"batch_job_mmlu_nano_paraphrase.jsonl\"), 'r') as f:\n",
    "\t\tlines = len(f.readlines())\n",
    "\t\n",
    "\trows = []\n",
    "\tstats = [0,0]\n",
    "\n",
    "\tf_ph = out_file(\"batch_job_mmlu_nano_paraphrase_result.jsonl\")\n",
    "\tf_a = out_file(\"batch_job_mmlu_nano_answer_original_result.jsonl\")\n",
    "\tf_ph_a = out_file(\"batch_job_mmlu_nano_answer_paraphrase_result.jsonl\")\n",
    "\n",
    "\tfor i in range(0,lines):\n",
    "\t\n",
    "\t\tdt_ph = get_line_file(f_ph,i,extract_data_paraphrase)\n",
    "\t\tdt_a = get_line_file(f_a,i,extract_data_paraphrase)\n",
    "\t\tdt_ph_a = get_line_file(f_ph_a,i,extract_data_paraphrase)\n",
    "\n",
    "\t\trow = df.iloc[i]\n",
    "\t\trows.append([\n",
    "       \t    row['instruction'],\n",
    "         \trow['option_a'],\n",
    "         \trow['option_b'],\n",
    "         \trow['option_c'],\n",
    "         \trow['option_d'],\n",
    "         \trow['answer'],\n",
    "\t\t\tdt_a[\"answer\"],\n",
    "\t\t\tclean_text(dt_ph[\"paraphrased_question\"]),\n",
    "\t\t\tclean_text(dt_ph[\"option_a\"]),\n",
    "\t\t\tclean_text(dt_ph[\"option_b\"]),\n",
    "\t\t\tclean_text(dt_ph[\"option_c\"]),\n",
    "\t\t\tclean_text(dt_ph[\"option_d\"]),\n",
    "\t\t\tdt_ph_a[\"answer\"],\n",
    "\t\t])\n",
    "\n",
    "\t\tif(row['answer'] == dt_a[\"answer\"]): stats[0]+=1\n",
    "\t\tif(row['answer'] == dt_ph_a[\"answer\"]): stats[1]+=1\n",
    "\t\n",
    "\t\n",
    "\tstats[0] = stats[0]/lines\n",
    "\tstats[1] = stats[1]/lines\n",
    "\t\n",
    "\tstats = pd.DataFrame([{'acuracy': stats[0],'acuracy_ph': stats[1],}])\n",
    "\treturn pd.DataFrame(rows),stats\n",
    "\n",
    "file_name = out_file('FinalResults_gpt41nano.xlsx')\n",
    "clean_dtset,stat = clean()\n",
    "\n",
    "\n",
    "with pd.ExcelWriter(file_name) as writer:\n",
    "\tclean_dtset.to_excel(writer, sheet_name='Results')\n",
    "\tstat.to_excel(writer, sheet_name='Stats',engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new_row = {\n",
    "       \t    'question': row['instruction'],\n",
    "         \t'A': row['option_a'],\n",
    "         \t'B': row['option_b'],\n",
    "         \t'C': row['option_c'],\n",
    "         \t'D': row['option_d'],\n",
    "         \t'correct_answer': row['answer'],\n",
    "\t\t\t'llm_answer': dt_a[\"answer\"],\n",
    "\t\t\t'question_prphr' : dt_ph[\"paraphrased_question\"],\n",
    "\t\t\t'A_prphr' : dt_ph[\"option_a\"],\n",
    "\t\t\t'B_prphr' : dt_ph[\"option_b\"],\n",
    "\t\t\t'C_prphr' : dt_ph[\"option_c\"],\n",
    "\t\t\t'D_prphr' : dt_ph[\"option_d\"],\n",
    "\t\t\t'llm_answer_prphr': dt_ph_a[\"answer\"],\n",
    "        }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
