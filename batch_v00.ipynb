{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "import json\n",
    "#import requests\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import openai\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI #estamos la clase concreta OpenAI del módulo openai\n",
    "from dotenv import load_dotenv #importamos una función concreta del módulo\n",
    "import os\n",
    "\n",
    "load_dotenv(\"template.env\")\n",
    "\n",
    "# Acceder a la clave de API de OpenAI\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Asegurarte de que la clave de API se haya cargado correctamente\n",
    "if api_key is None:\n",
    "    raise ValueError(\"La clave de API no está configurada en el archivo .env\")\n",
    "    \n",
    "client = OpenAI() #creando un objeto de la clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"MMLU_completo.xlsx\"\n",
    "\n",
    "df = pd.read_excel(dataset_path)\n",
    "#df = df.sample(20) #QUITAR ESTA LÍNEA PARA PROCESAR TODO EL DATASET\n",
    "df = df.sample(5) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorize_system_prompt = '''\n",
    "Your goal is to evaluate and paraphrase multiple choice questions from JSON objects. You will be provided with a JSON object containing a multiple choice question, and you will output two JSON objects: one with the evaluation of the original question and one with the paraphrased question and its evaluation.\n",
    "\n",
    "For each row, follow these steps:\n",
    "1. Evaluate the original question without paraphrasing.\n",
    "2. Paraphrase the question while maintaining the original meaning, ensuring the paraphrase is at least 500 characters long.\n",
    "3. Forget what you have done so far and exclusively answer the paraphrased question. The answer could be different from the original question, just answer what you think it is.\n",
    "\n",
    "The JSON objects should be in the following format:\n",
    "\n",
    "Original Evaluation:\n",
    "{\n",
    "    answer: string // The selected option key for the original question, limited to 'A', 'B', 'C', or 'D'\n",
    "}\n",
    "\n",
    "Paraphrased Evaluation:\n",
    "{\n",
    "    paraphrased_question: string // The paraphrased question\n",
    "    answer: string // The selected option key for the paraphrased question, limited to 'A', 'B', 'C', or 'D'\n",
    "}\n",
    "\n",
    "Ensure that the question is presented differently but conveys the same idea. Keep the JSON format in the answer with '{' and '}'.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    # Extraer las columnas necesarias del DataFrame\n",
    "    instruction = row['instruction']\n",
    "    option_a = row['option_a']\n",
    "    option_b = row['option_b']\n",
    "    option_c = row['option_c']\n",
    "    option_d = row['option_d']\n",
    "    \n",
    "    # Formar el JSON con las columnas extraídas\n",
    "    description = json.dumps({\n",
    "        \"instruction\": instruction,\n",
    "        \"options\": {\n",
    "            \"A\": option_a,\n",
    "            \"B\": option_b,\n",
    "            \"C\": option_c,\n",
    "            \"D\": option_d\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    task = {\n",
    "        \"custom_id\": f\"task-{index}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            # Esto es lo que tendrías en tu llamada a la API de Chat Completions\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"temperature\": 0,\n",
    "            \"response_format\": { \n",
    "                \"type\": \"json_object\"\n",
    "            },\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": categorize_system_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": description\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    tasks.append(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the file\n",
    "\n",
    "file_name = \"batch_tasks_mmlu.jsonl\"\n",
    "\n",
    "with open(file_name, 'w') as file:\n",
    "    for obj in tasks:\n",
    "        file.write(json.dumps(obj) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_file = client.files.create(\n",
    "  file=open(file_name, \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job = client.batches.create(\n",
    "  input_file_id=batch_file.id,\n",
    "  endpoint=\"/v1/chat/completions\",\n",
    "  completion_window=\"24h\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job = client.batches.retrieve(batch_job.id)\n",
    "print(batch_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARA CANCELAR UN BATCH\n",
    "# # ID del batch que deseas cancelar\n",
    "# batch_id = batch_job.id\n",
    "\n",
    "# # URL para cancelar el batch\n",
    "# url = f\"https://api.openai.com/v1/batches/{batch_id}/cancel\"\n",
    "\n",
    "# # Encabezados de la solicitud\n",
    "# headers = {\n",
    "#     \"Authorization\": f\"Bearer {api_key}\",\n",
    "#     \"Content-Type\": \"application/json\",\n",
    "# }\n",
    "\n",
    "# # Realiza la solicitud POST para cancelar el batch\n",
    "# response = requests.post(url, headers=headers)\n",
    "\n",
    "# # Maneja la respuesta\n",
    "# if response.status_code == 200:\n",
    "#     data = response.json()\n",
    "#     print(\"Batch cancelado exitosamente.\")\n",
    "#     print(\"Detalles del Batch:\")\n",
    "#     print(data)\n",
    "# else:\n",
    "#     print(f\"Error al cancelar el batch: {response.status_code}\")\n",
    "#     print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA EXTRAER LOS RESULTADOS\n",
    "result_file_id = batch_job.output_file_id\n",
    "print(batch_job.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = client.files.content(result_file_id).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_name = \"batch_job_results_mmlu.jsonl\"\n",
    "\n",
    "with open(result_file_name, 'wb') as file:\n",
    "    file.write(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
