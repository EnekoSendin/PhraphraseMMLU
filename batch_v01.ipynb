{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "import json\n",
    "#import requests\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import openai\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI #estamos la clase concreta OpenAI del módulo openai\n",
    "from dotenv import load_dotenv #importamos una función concreta del módulo\n",
    "import os\n",
    "\n",
    "load_dotenv(\"template.env\")\n",
    "\n",
    "# Acceder a la clave de API de OpenAI\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Asegurarte de que la clave de API se haya cargado correctamente\n",
    "if api_key is None:\n",
    "    raise ValueError(\"La clave de API no está configurada en el archivo .env\")\n",
    "    \n",
    "client = OpenAI() #creando un objeto de la clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"MMLU_completo.xlsx\"\n",
    "\n",
    "df = pd.read_excel(dataset_path)\n",
    "#df = df.sample(20) #QUITAR ESTA LÍNEA PARA PROCESAR TODO EL DATASET\n",
    "df = df.sample(5) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorize_system_prompt1 = '''\n",
    "Your goal is to evaluate multiple choice questions from JSON objects. You will be provided with a JSON object containing a multiple choice question and you will output a JSON object with the evaluation of the question.\n",
    "\n",
    "For each row evaluate the question.\n",
    "\n",
    "The output JSON objects should be in the following format:\n",
    "\n",
    "{\n",
    "    answer: string, // The selected option key for the question, limited to 'A', 'B', 'C', or 'D'\n",
    "}\n",
    "\n",
    "Keep the JSON format in the answer with '{' and '}'.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorize_system_prompt ='''\n",
    "Your goal is to paraphrase multiple choice questions from JSON objects. You will be provided with a JSON object containing a multiple choice question and you will output a JSON object with the reworded question.\n",
    "\n",
    "For each row paraphrase the question while maintaining the original meaning and paraphrase the options as well. Ensure the paraphrase is at least 500 characters long between options and question.\n",
    "\n",
    "The output JSON objects should be in the following format:\n",
    "\n",
    "{paraphrased_question: string, option_a: string, option_b: string,option_c: string,option_d: string,}\n",
    "\n",
    "Ensure that the question is presented differently but conveys the same idea. Keep the JSON format in the output with '{' and '}'.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    # Extraer las columnas necesarias del DataFrame\n",
    "    instruction = row['instruction']\n",
    "    option_a = row['option_a']\n",
    "    option_b = row['option_b']\n",
    "    option_c = row['option_c']\n",
    "    option_d = row['option_d']\n",
    "    \n",
    "    # Formar el JSON con las columnas extraídas\n",
    "    description = json.dumps({\n",
    "        \"instruction\": instruction,\n",
    "        \"options\": {\n",
    "            \"A\": option_a,\n",
    "            \"B\": option_b,\n",
    "            \"C\": option_c,\n",
    "            \"D\": option_d\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    task = {\n",
    "        \"custom_id\": f\"task-{index}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            # Esto es lo que tendrías en tu llamada a la API de Chat Completions\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"temperature\": 0,\n",
    "            \"response_format\": { \n",
    "                \"type\": \"json_object\"\n",
    "            },\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": categorize_system_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": description\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    tasks.append(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "\tprint(df.values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the file\n",
    "\n",
    "file_name = \"batch_tasks_mmlu.jsonl\"\n",
    "\n",
    "with open(file_name, 'w') as file:\n",
    "    for obj in tasks:\n",
    "        file.write(json.dumps(obj) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_file = client.files.create(\n",
    "  file=open(file_name, \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job = client.batches.create(\n",
    "  input_file_id=batch_file.id,\n",
    "  endpoint=\"/v1/chat/completions\",\n",
    "  completion_window=\"24h\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job = client.batches.retrieve(batch_job.id)\n",
    "print(batch_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARA CANCELAR UN BATCH\n",
    "# # ID del batch que deseas cancelar\n",
    "# batch_id = batch_job.id\n",
    "\n",
    "# # URL para cancelar el batch\n",
    "# url = f\"https://api.openai.com/v1/batches/{batch_id}/cancel\"\n",
    "\n",
    "# # Encabezados de la solicitud\n",
    "# headers = {\n",
    "#     \"Authorization\": f\"Bearer {api_key}\",\n",
    "#     \"Content-Type\": \"application/json\",\n",
    "# }\n",
    "\n",
    "# # Realiza la solicitud POST para cancelar el batch\n",
    "# response = requests.post(url, headers=headers)\n",
    "\n",
    "# # Maneja la respuesta\n",
    "# if response.status_code == 200:\n",
    "#     data = response.json()\n",
    "#     print(\"Batch cancelado exitosamente.\")\n",
    "#     print(\"Detalles del Batch:\")\n",
    "#     print(data)\n",
    "# else:\n",
    "#     print(f\"Error al cancelar el batch: {response.status_code}\")\n",
    "#     print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA EXTRAER LOS RESULTADOS\n",
    "result_file_id = batch_job.output_file_id\n",
    "print(batch_job.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = client.files.content(result_file_id).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_name = \"batch_job_results_mmlu.jsonl\"\n",
    "\n",
    "with open(result_file_name, 'wb') as file:\n",
    "    file.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonl_file = 'batch_job_results_mmlu.jsonl'\n",
    "data = []\n",
    "with open(jsonl_file, 'r') as file:\n",
    "    for line in file:\n",
    "        new_line = json.loads(line)\n",
    "        data.append(new_line)\n",
    "        #print(new_line)\n",
    "        \n",
    "test_1 = data[0]\n",
    "test_1 = test_1[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "test_1 = json.loads(test_1)\n",
    "instruct = test_1[\"paraphrased_question\"]\n",
    "op_a = test_1[\"option_a\"]\n",
    "op_b = test_1[\"option_b\"]\n",
    "op_c = test_1[\"option_c\"]\n",
    "op_d = test_1[\"option_d\"]\n",
    "print(instruct)\n",
    "print(op_a)\n",
    "print(op_b)\n",
    "print(op_c)\n",
    "print(op_d)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
